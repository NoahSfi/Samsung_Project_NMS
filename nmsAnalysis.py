

import glob
import numpy as np
import time
import tensorflow as tf
import json
from matplotlib import pyplot as plt
from object_detection.utils import ops as utils_ops
from object_detection.core import post_processing
from tqdm import tqdm
from PIL import Image, ImageDraw
from pycocotools.coco import COCO
from pycocotools.cocoeval import COCOeval
import copy
import os
utils_ops.tf = tf.compat.v1
# Patch the location of gfile
tf.gfile = tf.io.gfile


class nmsAnalysis:

    #The goal of this class is giving annotations and models, to compute the AP[IoU=0.5] depending 
    #on the IoU treshold that would be given inside a Non-Max-Suppression algorithm.

    #   Parameters:
    #    models:             - a list of paths redirecting to an OD model
    #    imagesPath:         - path redirecting to a folder containing images in the jpg format
    #    annotationPath:     - path redirecting to the annotation file describing the images given above
    #    catFocus:           - if set to None, it will analyse all the categories of objects given in the annotation file.
    #                               One can give a list of category of the form ["person","car"]
    #    number_IoU_thresh:  - number of different IoU treshold to analyse in between 0.2 and 0.9
    #    overall:            - if set to True it will compute the AP to IoU treshold for the overall given categories
    #    resFilePath:        - path to the json file where the detection results will be written in order to use COCOeval
    #    graph_precision_to_recall:  - If set to True will graph the precision to recall for every IoU
    #    with_train:         - if set to True will replace the ration fn/npig generated by the nms on the validation data set by the one of the training.
    #                           Please run groundTruthFN before setting it to True in order to have the informations requried. See doc for more infos.
    #    study:              - dictionnary containing the required current informations by the class when analysing a given model/category

    def __init__(self, models, imagesPath, annotationPath, catFocus=None, number_IoU_thresh=50, overall=False):
        """
        The goal of this class is giving annotations and models, to compute the AP[IoU=0.5] depending 
        on the IoU treshold that would be given inside a Non-Max-Suppression algorithm.
        
        Initialize nmsAnalysis
        :param models: list of paths redirecting to an OD model
        :param imagesPath: path redirecting to a folder containing images in the jpg format
        :param annotationPath: path redirecting to the annotation file describing the images given above
        :catFocus: if set to None, it will analyse all the categories of objects given in the annotation file. 
                    One can give a list of category of the form ["person","car"]
        :param number_IoU_thresh: number of different IoU treshold to analyse in betweem 0.2 and 0.9
        :param overall: if set to True will replace the ration fn/npig generated by the nms on the validation data set by the one of the training.
                        Please run groundTruthFN before setting it to True in order to have the informations requried. See doc for more infos.
        :return: None
        """
        assert(type(models) == list), print(
            "Please input a list of model path")

        self.models = models
        self.imagesPath = imagesPath
        self.annotationPath = annotationPath
        self.resFilePath = self._createResFilePath()
        self.number_IoU_thresh = number_IoU_thresh
        self.iou_thresholdXaxis = np.linspace(0.2, 0.9, number_IoU_thresh)
        self.overall = overall

        self.coco = self.loadCocoApi()  # coco object with ground truth annotations
        self.categories = self.getCategories() if catFocus is None else catFocus # list of categories to study

        # All the variable that will change throughout the study
        self._study = {
            "img": dict(),
            "catId": int(),
            "catStudied": str(),
            "all_output_dict": dict(),
            "modelPath": str(),
            "model": None,  # TF model
            "iouThreshold": float(),
        }

        # Can be changed after initialization
        self.graph_precision_to_recall = False
        self.with_train = False

    def _createResFilePath(self):
        """
        :return: path to the json file where the detection results will be written in order to use COCOeval
        """
        return "cocoDt.json"

    def loadModel(self, modelPath):
        """
        Load associate tf OD model
        :return: a trackable object from the tf librairy
        """
        model_dir = modelPath + "/saved_model"
        detection_model = tf.saved_model.load(str(model_dir))
        detection_model = detection_model.signatures['serving_default']
        general_folder = "{}/nms_analysis".format(modelPath)
        if not os.path.isdir(general_folder):
            os.mkdir(general_folder)
        
        return detection_model

    def loadCocoApi(self):
        """
        Read self.annotationPath and load coco associated to it
        :return: coco object
        """
        annFile = self.annotationPath
        # initialize COCO api for instance annotations
        coco = COCO(annFile)
        return coco

    def getCategories(self):
        """
        Load the categories present inside self.annotationPath
        :return: List of categories
        """
        cats = self.coco.loadCats(self.coco.getCatIds())
        categories = [cat['name'] for cat in cats]
        return categories

    def getImgClass(self, category):
        # 
        """
        Load all images information that contain the given category and the associated index.
        And update the self._study parameter.
        :param self._study["img"]: list containing dictionnaries element of the form: 
        
            {
                'license': 5, 
                'file_name': '000000100274.jpg', 
                'coco_url': 'http://images.cocodataset.org/val2017/000000100274.jpg', 
                'height': 427, 
                'width': 640, 
                'date_captured': '2013-11-17 08:29:54', 
                'flickr_url': 'http://farm8.staticflickr.com/7460/9267226612_d9df1e1d14_z.jpg', 
                'id': 100274
            }
        :param self.study["catId"]: Index associated to the input category
        :return: None
        """
        catIds = self.coco.getCatIds(catNms=[category])
        imgIds = self.coco.getImgIds(catIds=catIds)
        img = self.coco.loadImgs(imgIds)

        self._study["img"] = img
        self._study["catId"] = catIds[0]

    def getCatId(self, category):
        """
        :param category: category inside the dataset studied
        :return: associated index in the annotation
        """
        catIds = self.coco.getCatIds(catNms=[category])
        return catIds[0]

    def load_all_output_dict(self):

        """
        Write the dictionnary containing all detections made by the model studied inside a json if the file "all_outpout_dict.json" 
        is not existing inside the model folder in order to fast next use of the class with the same model. For more details look at
        `computeInferenceBbox`.
        
        If the file already exists then read it.
        
        Update self._study["all_output_dict"] to be equal to it.
        
        :return: None
        """
        self._study["model"] = self.loadModel(self._study["modelPath"])
        filename = self._study["modelPath"] + "/all_output_dict.json"
        is_all_output_dict = os.path.isfile(filename)
        if not is_all_output_dict:
            print("Compute all the inferences boxes in the validation set for the model {} and save it for faster computations of you reuse the interface in {}/all_output_dict.json".format(
                self._study["modelPath"], self._study["modelPath"]))
            all_output_dict = self.computeInferenceBbox(self._study["model"])
            with open(filename, 'w') as fs:
                json.dump(all_output_dict, fs, indent=1)
        else:
            with open(filename, 'r') as fs:
                all_output_dict = json.load(fs)
        self._study["all_output_dict"] = all_output_dict

    def expand_image_to_4d(self, image):
        """
        Expand a given image in 4d
        :param image: a numpy array representing a gray scale image
        :return: a numpy array representing the image in 4d
        """
        # The function supports only grayscale images
        assert len(image.shape) == 2, "Not a grayscale input image"
        last_axis = -1
        dim_to_repeat = 2
        repeats = 3
        grscale_img_3dims = np.expand_dims(image, last_axis)
        training_image = np.repeat(
            grscale_img_3dims, repeats, dim_to_repeat).astype('uint8')
        assert len(training_image.shape) == 3
        assert training_image.shape[-1] == 3
        return training_image

    def run_inference_for_single_image(self, image):
        """
        :param image: a numpy array representing an image in 4d
        
        :return:
            If image in right format an output_dict:
            
                key = ['num_detections','detection_classes','detection_boxes','detection_scores']
                
                valuesType = [int,list of int, list of 4 integers, list int]
            Else: None
        """
        image = np.asarray(image)
        # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.
        input_tensor = tf.convert_to_tensor(image)
        # The model expects a batch of images, so add an axis with `tf.newaxis`.
        input_tensor = input_tensor[tf.newaxis, ...]

        # Run inference
        # If image doesn't respect the right format ignore it
        try:
            output_dict = self._study["model"](input_tensor)
        except:
            return None

        # All outputs are batches tensors.
        # Convert to numpy arrays, and take index [0] to remove the batch dimension.
        # We're only interested in the first num_detections.
        num_detections = int(output_dict.pop('num_detections'))
        output_dict = {key: value[0, :num_detections].numpy()
                       for key, value in output_dict.items()}

        key_of_interest = ['detection_scores',
                           'detection_classes', 'detection_boxes']
        output_dict = {key: list(output_dict[key]) for key in key_of_interest}
        output_dict["num_detections"] = int(num_detections)
        output_dict['detection_boxes'] = [[float(box) for box in output_dict['detection_boxes'][i]] for i in range(
            len(output_dict['detection_scores']))]
        output_dict['detection_scores'] = [
            float(box) for box in output_dict['detection_scores']]
        output_dict['detection_classes'] = [
            float(box) for box in output_dict['detection_classes']]

        if len(output_dict["detection_boxes"]) == 0:
            return None
        return output_dict

    def computeInferenceBbox(self):
        """
        For all the images in the coco img, compute the output_dict with
        `run_inference_for_single_image`. Store them as a dictionnary with keys
        being the index of the image in our coco dataset.

        :return:
        A dictionnary describing the inferences for each image:
        {id: keyDic = ['num_detections','detection_classes','detection_boxes',
                    'detection_scores']}
        """
        all_output_dict = dict()
        i = 0
        folder = "/".join([self.imagesPath, "*.jpg"])
        for image_path in tqdm(glob.glob(folder)):
            # the array based representation of the image
            image = Image.open(image_path)
            image_np = np.array(image)
            """If image is gray_scale one need to reshape to dimension 4
            using the utility function defined above"""
            if len(image_np.shape) == 2:
                image_np = self.expand_image_to_4d(image_np)
            # Actual detection.
            output_dict = self.run_inference_for_single_image(image_np)
            if output_dict is None:
                continue
            idx = image_path.split("/")[-1]
            all_output_dict[idx] = output_dict
            i += 1
        return all_output_dict

    def computeNMS(self, output_dict):
        """
        Apply the non max suppresion on the given detections of an image. The IoU treshold used is `self._study[iouThreshold]` updated in 
        `getClassAP` or `getOverallAP`.
        
        input:
        ----------
        - output_dict: the dictionnary ouput of the inference computation
        keyDic = ['num_detections','detection_classes','detection_boxes','detection_scores']

        output:
        ----------
        A 3D tuple in this order:
        - final_classes : list of int64 telling the category of each detected bbox
        - final_scores : list of float64 scoring each bbox
        - final_boxes : list of coordinates of each bbox (format : [ymin,xmin,ymax,xmax] )
        """

        if not output_dict:
            return None, None, None

        # Apply the nms
        box_selection = tf.image.non_max_suppression_with_scores(
            output_dict['detection_boxes'], output_dict['detection_scores'], 100,
            iou_threshold=float(self._study["iouThreshold"]), score_threshold=float(
                '-inf'),
            soft_nms_sigma=0.0, name=None)

        # Index in the list output_dict['detection_boxes']
        final_boxes = list(box_selection[0].numpy())
        # Index in the list output_dict['detection_scores']
        final_scores = list(box_selection[1].numpy())
        final_classes = []
        for i in range(len(final_boxes)):
            index = final_boxes[i]
            # We want the actual bbox coordinate not the index
            final_boxes[i] = output_dict['detection_boxes'][index]
            final_classes.append(output_dict['detection_classes'][index])

        return final_classes, final_scores, final_boxes

    def putCOCOformat(self, boxes, im_width, im_height):
        """
        Transform a bbox in the tensorflow OD format into cocoformat
        input:
        ----------
        -  boxes: List of the form [ymin,xmin,ymax,xmax] in the percentage of the image scale
        -  im_width: real width of the associated image
        -  im_height: real height of the associated image
        
        output:
        ----------
        -   List of the form [left,top,width,height] describing the bbox, in the image scale
        """
        # float to respect json format
        left = float(boxes[1]) * im_width
        right = float(boxes[3]) * im_width
        top = float(boxes[0]) * im_height
        bottom = float(boxes[2]) * im_height
        width = right - left
        height = bottom - top

        return [left, top, width, height]

    def writeResJson(self, newFile=True):
        """
        Write a `self.resFilePath` in the coco annotations format describing final detections for a unique category after having applied `computeNMS`.

        input:
        ----------
        - newFile: if set to True rewrite the file else append the detections to the file
            
        output:
        ----------
        - List of the image ids that are studied
        """
        result = []
        imgIds = set()  # set to avoid repetition
        key_of_interest = ['detection_scores',
                           'detection_classes', 'detection_boxes']
        for img in self._study["img"]:
            imgId = img["id"]
            imgIds.add(imgId)

            output_dict = copy.deepcopy(
                self._study["all_output_dict"][img['file_name']])
            if output_dict == None:
                continue

            # remove detection of other classes that are not studied
            idx_to_remove = [i for i, x in enumerate(
                output_dict["detection_classes"]) if x != self._study["catId"]]
            for index in sorted(idx_to_remove, reverse=True):
                del output_dict['detection_scores'][index]
                del output_dict['detection_classes'][index]
                del output_dict['detection_boxes'][index]
                output_dict["num_detections"] -= 1
            num_detections = output_dict["num_detections"]
            output_dict = {key: np.array(
                output_dict[key]) for key in key_of_interest}
            output_dict["num_detections"] = num_detections
            if len(output_dict['detection_boxes']) == 0:
                output_dict = None

            final_classes, final_scores, final_boxes = self.computeNMS(
                output_dict)

            if not final_classes:
                continue

            for j in range(len(final_classes)):

                #ex : {"image_id":42,"category_id":18,"bbox":[258.15,41.29,348.26,243.78],"score":0.236}
                properties = {}
                # json format doesnt support int64
                properties["category_id"] = int(final_classes[j])
                properties["image_id"] = imgId
                im_width = img['width']
                im_height = img['height']
                # we want [ymin,xmin,ymax,xmax] -> [xmin,ymin,width,height]
                properties["bbox"] = self.putCOCOformat(
                    final_boxes[j], im_width, im_height)
                properties["score"] = float(final_scores[j])

                result.append(properties)
        if newFile:
            with open(self.resFilePath, 'w') as fs:
                json.dump(result, fs, indent=1)
        else:
            with open(self.resFilePath, 'r') as fs:
                data = json.load(fs)
                result += data
            with open(self.resFilePath, 'w') as fs:
                json.dump(result, fs, indent=1)

        return list(imgIds)

    def getClassAP(self):
        """
        Evaluate `self._study["catStudied"]` for different IoU. Write the result inside modelPath/nms_analysis.
        
        - if `self.withTrain` set to True will it will replace the ration fn/npig generated by the nms on the validation data set by the one of the training when computing the AP.
            Please run groundTruthFN before setting it to True in order to have the informations requried. See doc for more infos.
        
        :return: None
        """

        AP = []
        FN = []
        computeInstances = True
        for iouThreshold in tqdm(self.iou_thresholdXaxis, desc="progressbar IoU Threshold"):

            self._study["iouThreshold"] = iouThreshold
            imgIds = self.writeResJson()
            try:
                # Load cocoapi object for the detections
                cocoDt = self.coco.loadRes(self.resFilePath)
            except:
                return None
            # load COCOeval object to compare groundtruth and detections
            cocoEval = COCOeval(self.coco, cocoDt, 'bbox')
            cocoEval.params.imgIds = imgIds
            cocoEval.params.catIds = self._study["catId"]
            # Here we increase the maxDet to 1000 (same as in model config file)
            # Because we want to optimize the nms that is normally in charge of dealing with
            # bbox that detects the same object twice or detection that are not very precise
            # compared to the best one.
            cocoEval.params.maxDets = [1, 10, 1000]
            cocoEval.evaluate()
            # Count the number of false negatives and number of instances
            number_FN = 0
            if computeInstances:
                instances_non_ignored = 0
            for evalImg in cocoEval.evalImgs:
                number_FN += sum(evalImg["FN"])
                if computeInstances:
                    instances_non_ignored += sum(
                        np.logical_not(evalImg['gtIgnore']))
            computeInstances = False
            FN.append(int(number_FN))
            cocoEval.accumulate(
                iouThreshold, withTrain=self.with_train, category=self._study["catStudied"])

            cocoEval.summarize()
            # readDoc and find self.evals
            AP.append(cocoEval.stats[1])
            precisions = cocoEval.s.reshape((101,))
            if self.graph_precision_to_recall:
                self.precisionToRecall(precisions)

        # Create folder if necessary and write result
        
        general_folder = "{}/nms_analysis".format(self._study["modelPath"])
        if not os.path.isdir(general_folder):
            os.mkdir(general_folder)
        general_folder += "/AP[IoU=0.5]/"
        if not os.path.isdir(general_folder):
            os.mkdir(general_folder)

        if not self.with_train:
            general_folder += "validation/"
        else:
            general_folder += "validation_train/"
        if not os.path.isdir(general_folder):
            os.mkdir(general_folder)

        with open(general_folder + "{}.json".format(self._study["catStudied"]), 'w') as fs:
            json.dump({"iou threshold": list(self.iou_thresholdXaxis), "AP[IoU:0.5]": AP, "False Negatives": FN,
                       "number of instances": int(instances_non_ignored)}, fs, indent=1)

    def getOverallAP(self):
        """
        
        Evaluate all `self.categories` for different IoU. Write the result inside modelPath/nms_analysis/AP[IoU=0.5]/all.json
        
        :return: None
    
        """

        AP = []
        FN = []
        computeInstances = True

        for iouThreshold in tqdm(self.iou_thresholdXaxis, desc="progressbar IoU Threshold"):
            self._study["iouThreshold"] = iouThreshold
            allCatIds = []
            allImgIds = []
            for i, category in tqdm(enumerate(self.categories), desc="category"):

                self.getImgClass(category)
                allCatIds += [self._study["catId"]]
            # Create the Json result file and read it.
                if i == 0:
                    imgIds = self.writeResJson(newFile=True)

                else:
                    imgIds = self.writeResJson(newFile=False)
                allImgIds += imgIds
            try:
                cocoDt = self.coco.loadRes(self.resFilePath)
            except:
                return 1
            cocoEval = COCOeval(self.coco, cocoDt, 'bbox')
            cocoEval.params.imgIds = allImgIds
            cocoEval.params.catIds = allCatIds
            # Here we increase the maxDet to 1000 (same as in model config file)
            # Because we want to optimize the nms that is normally in charge of dealing with
            # bbox that detects the same object twice or detection that are not very precise
            # compared to the best one.
            cocoEval.params.maxDets = [1, 10, 1000]
            cocoEval.evaluate()
            number_FN = 0
            if computeInstances:
                instances_non_ignored = 0

            for evalImg in cocoEval.evalImgs:
                if evalImg != None:
                    number_FN += sum(evalImg["FN"])
                    if computeInstances:
                        instances_non_ignored += sum(
                            np.logical_not(evalImg['gtIgnore']))
            computeInstances = False
            FN.append(int(number_FN))
            cocoEval.accumulate(iouThreshold, withTrain=False, category='all')

            cocoEval.summarize()
            # readDoc and find self.evals
            AP.append(cocoEval.stats[1])

        general_folder = "{}/nms_analysis/AP[IoU=0.5]/".format(
            self._study["modelPath"])
        if not os.path.isdir(general_folder):
            os.mkdir(general_folder)

        if not self.with_train:
            general_folder += "validation/"
        else:
            general_folder += "validation_train/"
        if not os.path.isdir(general_folder):
            os.mkdir(general_folder)
        with open(general_folder + "all.json", 'w') as fs:
            json.dump({"iou threshold": list(self.iou_thresholdXaxis), "AP[IoU:0.5]": AP, "False Negatives": FN,
                       "number of instances": int(instances_non_ignored)}, fs, indent=1)

        return 0

    def precisionToRecall(self, precision):
        """
        Graph the precision to recall for `self._study[IoUThreshold]`
        
        :param precision: -[all] P = 101. Precision for each recall
        :return: None
        """
        plt.figure(figsize=(18, 10))
        recall = np.linspace(0, 1, 101)
        iouThreshold = round(self._study["iouThreshold"], 3)

        # Plot the data
        plt.plot(recall, precision,
                 label='Precision to recall for IoU = {}'.format(iouThreshold))
        # Add a legend
        plt.legend(loc="lower left")
        plt.title('Class = {}'.format(self._study["catStudied"]))
        plt.xlabel('Recall')
        plt.ylabel('Precision')

        # Create correct folder
        general_folder = "{}/nms_analysis/precision_to_recall/".format(
            self._study["modelPath"])
        if not os.path.isdir(general_folder):
            os.mkdir(general_folder)

        if self.with_train:
            general_folder += "validation_train/"
        else:
            general_folder += "validation/"

        if not os.path.isdir(general_folder):
            os.mkdir(general_folder)

        category_folder = general_folder + \
            self._study["catStudied"].replace(' ', '_')
        if not os.path.isdir(category_folder):
            os.mkdir(category_folder)

        plt.savefig(category_folder +
                    '/iou={}.png'.format(iouThreshold), bbox_inches='tight')

        # plt.clf()
        plt.close('all')

    def runAnalysis(self):
        """
        Run the analysis for the given models and categories onto the given validation set.
        :return: None
        """
        if self.with_train:
            if not os.path.isdir('FN_with_nms/'):
                print(
                    "Please run analysis on the groundtruth in order to know the number of false negatives genreated by nms.")
                return
        for modelPath in self.models:
            self._study["modelPath"] = modelPath
            self.load_all_output_dict()
            for catStudied in tqdm(self.categories, desc="Categories Processed", leave=False):
                self._study["catStudied"] = catStudied
                self.getImgClass(catStudied)
                self.getClassAP()
            if self.overall and not self.with_train:
                self.getOverallAP()

        os.remove(self.resFilePath)
